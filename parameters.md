# Transformers-With-TensorFlow2 Parameters

## Attention



## Bert Config

- `attention_probs_dropout_prob`
- `hidden_act`
- `hidden_dropout_prob`
- `hidden_size`
- `initializer_range`
- `intermediate_size`
- `max_position_embeddings`
- `num_attention_heads`
- `num_hidden_layers`
- `type_vocab_size`
- `vocab_size`

